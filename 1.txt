`bottleneck` is a tool that can be used as an initial step for debugging
bottlenecks in your program.

It summarizes runs of your script with the Python profiler and PyTorch's
autograd profiler. Because your script will be profiled, please ensure that it
exits in a finite amount of time.

For more complicated uses of the profilers, please see
https://docs.python.org/3/library/profile.html and
https://pytorch.org/docs/main/autograd.html#profiler for more information.
Running environment analysis...
Running your script with cProfile
using apple M silicon......
('algorithm', 'fed_twins')
('gpu', 0)
('seed', 13)
('save_dir', './record/')
('rounds2', 50)
('local_ep', 5)
('frac2', 0.1)
('num_users', 100)
('local_bs', 32)
('lr', 0.1)
('model', 'lenet')
('num_classes', 10)
('level_n_system', 0.5)
('level_n_lowerb', 0.3)
('alpha_dirichlet', 10)
('non_iid_prob_class', 0.7)
('dataset', 'mnist')
('iid', False)
('plr', 0.05)
('lamda', 15)
('K', 5)
('gamma', 1)
('begin_sel', 10)
('max_beta', 2.0)
('correction', True)
('correction_begin_round', 25)
('LID_k', 20)
('iteration1', 5)
('rounds1', 200)
('frac1', 0.01)
('pretrained', False)
('mixup', False)
('alpha', 1)
('beta', 5)
('relabel_ratio', 0.5)
('confidence_thres', 0.5)
('clean_set_thres', 0.1)
('fine_tuning', True)
('T_pl', 100)
('lambda_cen', 1.0)
('lambda_e', 0.8)
('num_gradual', 10)
('forget_rate', 0.2)
('lr_decay', 0.1)
('schedule', [])
('momentum', 0.5)
('weight_decay', 0.0001)
('feature_dim', 128)
('mu', 0.01)
('unsupervised', False)
('device', device(type='mps'))
Client 0, noise level: 0.7877 (0.7089), real noise ratio: 0.6760
Client 2, noise level: 0.4944 (0.4450), real noise ratio: 0.4566
Client 3, noise level: 0.4635 (0.4172), real noise ratio: 0.4033
Client 4, noise level: 0.8920 (0.8028), real noise ratio: 0.7740
Client 6, noise level: 0.7822 (0.7040), real noise ratio: 0.6747
Client 7, noise level: 0.4074 (0.3667), real noise ratio: 0.3559
Client 8, noise level: 0.4425 (0.3983), real noise ratio: 0.3989
Client 9, noise level: 0.3473 (0.3126), real noise ratio: 0.3187
Client 13, noise level: 0.4574 (0.4116), real noise ratio: 0.3957
Client 15, noise level: 0.3237 (0.2913), real noise ratio: 0.2700
Client 20, noise level: 0.7283 (0.6555), real noise ratio: 0.6597
Client 23, noise level: 0.5618 (0.5056), real noise ratio: 0.5029
Client 26, noise level: 0.8716 (0.7844), real noise ratio: 0.7746
Client 27, noise level: 0.3558 (0.3202), real noise ratio: 0.3325
Client 29, noise level: 0.8867 (0.7980), real noise ratio: 0.8052
Client 30, noise level: 0.6949 (0.6254), real noise ratio: 0.6214
Client 32, noise level: 0.4015 (0.3614), real noise ratio: 0.3472
Client 33, noise level: 0.3690 (0.3321), real noise ratio: 0.3561
Client 35, noise level: 0.7970 (0.7173), real noise ratio: 0.7015
Client 38, noise level: 0.5606 (0.5045), real noise ratio: 0.4961
Client 41, noise level: 0.7353 (0.6618), real noise ratio: 0.6556
Client 42, noise level: 0.8045 (0.7240), real noise ratio: 0.7367
Client 47, noise level: 0.4586 (0.4127), real noise ratio: 0.4013
Client 48, noise level: 0.5133 (0.4620), real noise ratio: 0.4493
Client 50, noise level: 0.7860 (0.7074), real noise ratio: 0.6998
Client 51, noise level: 0.3370 (0.3033), real noise ratio: 0.2847
Client 56, noise level: 0.5591 (0.5031), real noise ratio: 0.4774
Client 57, noise level: 0.6532 (0.5879), real noise ratio: 0.5763
Client 59, noise level: 0.3915 (0.3523), real noise ratio: 0.3880
Client 60, noise level: 0.8911 (0.8020), real noise ratio: 0.7955
Client 62, noise level: 0.4187 (0.3768), real noise ratio: 0.3587
Client 67, noise level: 0.3696 (0.3326), real noise ratio: 0.3556
Client 68, noise level: 0.9393 (0.8454), real noise ratio: 0.8413
Client 69, noise level: 0.7046 (0.6341), real noise ratio: 0.5979
Client 72, noise level: 0.3069 (0.2762), real noise ratio: 0.2337
Client 75, noise level: 0.7848 (0.7064), real noise ratio: 0.6826
Client 78, noise level: 0.3984 (0.3586), real noise ratio: 0.3416
Client 79, noise level: 0.7685 (0.6916), real noise ratio: 0.6914
Client 80, noise level: 0.5127 (0.4614), real noise ratio: 0.4661
Client 83, noise level: 0.4420 (0.3978), real noise ratio: 0.4267
Client 88, noise level: 0.4144 (0.3729), real noise ratio: 0.3846
Client 90, noise level: 0.4952 (0.4457), real noise ratio: 0.4523
Client 91, noise level: 0.4432 (0.3989), real noise ratio: 0.4122
Client 94, noise level: 0.3650 (0.3285), real noise ratio: 0.3230
Client 98, noise level: 0.5071 (0.4564), real noise ratio: 0.4562
Client 99, noise level: 0.4163 (0.3747), real noise ratio: 0.3934
Rounds 0 early training:
Round 0 train loss  1.7174
Round 0 global test acc  49.7500 

Rounds 1 early training:
Round 1 train loss  1.3719
Round 1 global test acc  48.4200 

Rounds 2 early training:
Round 2 train loss  0.9139
Round 2 global test acc  39.0400 

Rounds 3 early training:
Round 3 train loss  -0.8181
Round 3 global test acc  65.0800 

Rounds 4 early training:
Round 4 train loss  -0.2451
Round 4 global test acc  49.1700 

Rounds 5 early training:
Round 5 train loss  -2.4623
Round 5 global test acc  63.9700 

Rounds 6 early training:
Round 6 train loss  -9.9910
Round 6 global test acc  66.6500 

Rounds 7 early training:
Round 7 train loss  -10.9371
Round 7 global test acc  79.1300 

Rounds 8 early training:
Round 8 train loss  -15.1925
Round 8 global test acc  82.7100 

Rounds 9 early training:
Round 9 train loss  -15.3070
Round 9 global test acc  72.2100 

Rounds 10 early training:
Round 10 train loss  -21.1417
Round 10 global test acc  91.4800 

Rounds 11 filter noisy data:
Round 11 train loss  -29.8499
Round 11 global test acc  93.3900 

Rounds 12 filter noisy data:
Round 12 train loss  -31.8987
Round 12 global test acc  91.6800 

Rounds 13 filter noisy data:
Round 13 train loss  -31.7457
Round 13 global test acc  93.2100 

Rounds 14 filter noisy data:
Round 14 train loss  -31.7587
Round 14 global test acc  89.9600 

Rounds 15 filter noisy data:
Round 15 train loss  -31.6763
Round 15 global test acc  94.9500 

Rounds 16 filter noisy data:
Round 16 train loss  -31.9234
Round 16 global test acc  94.9700 

Rounds 17 filter noisy data:
Round 17 train loss  -31.1698
Round 17 global test acc  94.1100 

Rounds 18 filter noisy data:
Round 18 train loss  -31.8018
Round 18 global test acc  94.8400 

Rounds 19 filter noisy data:
Round 19 train loss  -32.4395
Round 19 global test acc  94.6000 

Rounds 20 filter noisy data:
Round 20 train loss  -31.3932
Round 20 global test acc  94.9100 

Rounds 21 filter noisy data:
Round 21 train loss  -31.8646
Round 21 global test acc  95.8300 

Rounds 22 filter noisy data:
Round 22 train loss  -30.4885
Round 22 global test acc  94.8700 

Rounds 23 filter noisy data:
Round 23 train loss  -32.0689
Round 23 global test acc  95.9300 

Rounds 24 filter noisy data:
Round 24 train loss  -31.6630
Round 24 global test acc  95.0300 

Rounds 25 filter noisy data:
Round 25 train loss  -31.6973
Round 25 global test acc  96.3000 

Rounds 26 filter noisy data:
Round 26 train loss  -31.9964
Round 26 global test acc  95.8000 

Rounds 27 filter noisy data:
Round 27 train loss  -32.1735
Round 27 global test acc  95.8200 

Rounds 28 filter noisy data:
Round 28 train loss  -32.1281
Round 28 global test acc  95.3700 

Rounds 29 filter noisy data:
Round 29 train loss  -32.2366
Round 29 global test acc  96.0600 

Rounds 30 filter noisy data:
Round 30 train loss  -32.6858
Round 30 global test acc  95.6900 

Rounds 31 filter noisy data:
Round 31 train loss  -31.2193
Round 31 global test acc  94.3000 

Rounds 32 filter noisy data:
Round 32 train loss  -31.8447
Round 32 global test acc  93.9200 

Rounds 33 filter noisy data:
Round 33 train loss  -32.4858
Round 33 global test acc  95.6200 

Rounds 34 filter noisy data:
Round 34 train loss  -32.0355
Round 34 global test acc  95.3400 

Rounds 35 filter noisy data:
Round 35 train loss  -32.6345
Round 35 global test acc  96.3400 

Rounds 36 filter noisy data:
Round 36 train loss  -31.9429
Round 36 global test acc  96.2700 

Rounds 37 filter noisy data:
Round 37 train loss  -32.5433
Round 37 global test acc  96.5500 

Rounds 38 filter noisy data:
Round 38 train loss  -32.6204
Round 38 global test acc  96.8400 

Rounds 39 filter noisy data:
Round 39 train loss  -32.5436
Round 39 global test acc  96.2900 

Rounds 40 filter noisy data:
Round 40 train loss  -32.0779
Round 40 global test acc  95.8900 

Rounds 41 filter noisy data:
Round 41 train loss  -32.7222
Round 41 global test acc  96.6600 

Rounds 42 filter noisy data:
Round 42 train loss  -32.0446
Round 42 global test acc  96.4800 

Rounds 43 filter noisy data:
Round 43 train loss  -32.4253
Round 43 global test acc  96.6400 

Rounds 44 filter noisy data:
Round 44 train loss  -32.0472
Round 44 global test acc  96.5500 

Rounds 45 filter noisy data:
Round 45 train loss  -32.1547
Round 45 global test acc  96.4300 

Rounds 46 filter noisy data:
Round 46 train loss  -32.1953
Round 46 global test acc  90.6900 

Rounds 47 filter noisy data:
Round 47 train loss  -32.0610
Round 47 global test acc  96.3000 

Rounds 48 filter noisy data:
Round 48 train loss  -32.1621
Round 48 global test acc  96.2500 

Rounds 49 filter noisy data:
Round 49 train loss  -32.4078
Round 49 global test acc  95.5600 

Round 49 f_score 

[tensor(0.9832), tensor(0.9826), tensor(0.9907), tensor(0.9820), tensor(0.9699), tensor(0.9793), tensor(0.9859), tensor(0.9897), tensor(0.9856), tensor(0.9765), tensor(0.9798), tensor(0.9777), tensor(0.9794), tensor(0.9804), tensor(0.9854), tensor(0.9848), tensor(0.9928), tensor(0.9847), tensor(0.9799), tensor(0.9741), tensor(0.9787), tensor(0.9756), tensor(0.9901), tensor(0.9847), tensor(0.9834), tensor(0.9821), tensor(0.9507), tensor(0.9765), tensor(0.9828), tensor(0.9742), tensor(0.9700), tensor(0.9910), tensor(0.9763), tensor(0.9697), tensor(0.9896), tensor(0.9669), tensor(0.9855), tensor(0.9808), tensor(0.9923), tensor(0.9743), tensor(0.9879), tensor(0.9527), tensor(0.9604), tensor(0.9612), tensor(0.9817), tensor(0.9796), tensor(0.9833), tensor(0.9841), tensor(0.9635), tensor(0.9853), tensor(0.9720), tensor(0.9772), tensor(0.9845), tensor(0.9884), tensor(0.9890), tensor(0.9848), tensor(0.9711), tensor(0.9799), tensor(0.9774), tensor(0.9894), tensor(0.9766), tensor(0.9783), tensor(0.9759), tensor(0.9854), tensor(0.9759), tensor(0.9859), tensor(0.9840), tensor(0.9676), tensor(0.9623), tensor(0.9786), tensor(0.9791), tensor(0.9876), tensor(0.9863), tensor(0.9829), tensor(0.9809), tensor(0.9808), tensor(0.9833), tensor(0.9880), tensor(0.9916), tensor(0.9603), tensor(0.9736), tensor(0.9887), tensor(0.9767), tensor(0.9775), tensor(0.9796), tensor(0.9866), tensor(0.9791), tensor(0.9773), tensor(0.9751), tensor(0.9869), tensor(0.9784), tensor(0.9848), tensor(0.9782), tensor(0.9756), tensor(0.9885), tensor(0.9820), tensor(0.9771), tensor(0.9846), tensor(0.9753), tensor(0.9797)]
time: 74780.76627922058
Running your script with the autograd profiler...
using apple M silicon......
('algorithm', 'fed_twins')
('gpu', 0)
('seed', 13)
('save_dir', './record/')
('rounds2', 50)
('local_ep', 5)
('frac2', 0.1)
('num_users', 100)
('local_bs', 32)
('lr', 0.1)
('model', 'lenet')
('num_classes', 10)
('level_n_system', 0.5)
('level_n_lowerb', 0.3)
('alpha_dirichlet', 10)
('non_iid_prob_class', 0.7)
('dataset', 'mnist')
('iid', False)
('plr', 0.05)
('lamda', 15)
('K', 5)
('gamma', 1)
('begin_sel', 10)
('max_beta', 2.0)
('correction', True)
('correction_begin_round', 25)
('LID_k', 20)
('iteration1', 5)
('rounds1', 200)
('frac1', 0.01)
('pretrained', False)
('mixup', False)
('alpha', 1)
('beta', 5)
('relabel_ratio', 0.5)
('confidence_thres', 0.5)
('clean_set_thres', 0.1)
('fine_tuning', True)
('T_pl', 100)
('lambda_cen', 1.0)
('lambda_e', 0.8)
('num_gradual', 10)
('forget_rate', 0.2)
('lr_decay', 0.1)
('schedule', [])
('momentum', 0.5)
('weight_decay', 0.0001)
('feature_dim', 128)
('mu', 0.01)
('unsupervised', False)
('device', device(type='mps'))
Client 0, noise level: 0.7877 (0.7089), real noise ratio: 0.6760
Client 2, noise level: 0.4944 (0.4450), real noise ratio: 0.4566
Client 3, noise level: 0.4635 (0.4172), real noise ratio: 0.4033
Client 4, noise level: 0.8920 (0.8028), real noise ratio: 0.7740
Client 6, noise level: 0.7822 (0.7040), real noise ratio: 0.6747
Client 7, noise level: 0.4074 (0.3667), real noise ratio: 0.3559
Client 8, noise level: 0.4425 (0.3983), real noise ratio: 0.3989
Client 9, noise level: 0.3473 (0.3126), real noise ratio: 0.3187
Client 13, noise level: 0.4574 (0.4116), real noise ratio: 0.3957
Client 15, noise level: 0.3237 (0.2913), real noise ratio: 0.2700
Client 20, noise level: 0.7283 (0.6555), real noise ratio: 0.6597
Client 23, noise level: 0.5618 (0.5056), real noise ratio: 0.5029
Client 26, noise level: 0.8716 (0.7844), real noise ratio: 0.7746
Client 27, noise level: 0.3558 (0.3202), real noise ratio: 0.3325
Client 29, noise level: 0.8867 (0.7980), real noise ratio: 0.8052
Client 30, noise level: 0.6949 (0.6254), real noise ratio: 0.6214
Client 32, noise level: 0.4015 (0.3614), real noise ratio: 0.3472
Client 33, noise level: 0.3690 (0.3321), real noise ratio: 0.3561
Client 35, noise level: 0.7970 (0.7173), real noise ratio: 0.7015
Client 38, noise level: 0.5606 (0.5045), real noise ratio: 0.4961
Client 41, noise level: 0.7353 (0.6618), real noise ratio: 0.6556
Client 42, noise level: 0.8045 (0.7240), real noise ratio: 0.7367
Client 47, noise level: 0.4586 (0.4127), real noise ratio: 0.4013
Client 48, noise level: 0.5133 (0.4620), real noise ratio: 0.4493
Client 50, noise level: 0.7860 (0.7074), real noise ratio: 0.6998
Client 51, noise level: 0.3370 (0.3033), real noise ratio: 0.2847
Client 56, noise level: 0.5591 (0.5031), real noise ratio: 0.4774
Client 57, noise level: 0.6532 (0.5879), real noise ratio: 0.5763
Client 59, noise level: 0.3915 (0.3523), real noise ratio: 0.3880
Client 60, noise level: 0.8911 (0.8020), real noise ratio: 0.7955
Client 62, noise level: 0.4187 (0.3768), real noise ratio: 0.3587
Client 67, noise level: 0.3696 (0.3326), real noise ratio: 0.3556
Client 68, noise level: 0.9393 (0.8454), real noise ratio: 0.8413
Client 69, noise level: 0.7046 (0.6341), real noise ratio: 0.5979
Client 72, noise level: 0.3069 (0.2762), real noise ratio: 0.2337
Client 75, noise level: 0.7848 (0.7064), real noise ratio: 0.6826
Client 78, noise level: 0.3984 (0.3586), real noise ratio: 0.3416
Client 79, noise level: 0.7685 (0.6916), real noise ratio: 0.6914
Client 80, noise level: 0.5127 (0.4614), real noise ratio: 0.4661
Client 83, noise level: 0.4420 (0.3978), real noise ratio: 0.4267
Client 88, noise level: 0.4144 (0.3729), real noise ratio: 0.3846
Client 90, noise level: 0.4952 (0.4457), real noise ratio: 0.4523
Client 91, noise level: 0.4432 (0.3989), real noise ratio: 0.4122
Client 94, noise level: 0.3650 (0.3285), real noise ratio: 0.3230
Client 98, noise level: 0.5071 (0.4564), real noise ratio: 0.4562
Client 99, noise level: 0.4163 (0.3747), real noise ratio: 0.3934
Rounds 0 early training:
Round 0 train loss  1.7174
Round 0 global test acc  49.7500 

Rounds 1 early training:
Round 1 train loss  1.3719
Round 1 global test acc  48.4200 

Rounds 2 early training:
Round 2 train loss  0.9139
Round 2 global test acc  39.0400 

Rounds 3 early training:
Round 3 train loss  -0.8181
Round 3 global test acc  65.0800 

Rounds 4 early training:
Round 4 train loss  -0.2451
Round 4 global test acc  49.1700 

Rounds 5 early training:
Round 5 train loss  -2.4623
Round 5 global test acc  63.9700 

Rounds 6 early training:
Round 6 train loss  -9.9910
Round 6 global test acc  66.6500 

Rounds 7 early training:
Round 7 train loss  -10.9371
Round 7 global test acc  79.1300 

Rounds 8 early training:
Round 8 train loss  -15.1925
Round 8 global test acc  82.7100 

Rounds 9 early training:
Round 9 train loss  -15.3070
Round 9 global test acc  72.2100 

Rounds 10 early training:
Round 10 train loss  -21.1417
Round 10 global test acc  91.4800 

Rounds 11 filter noisy data:
Round 11 train loss  -29.8499
Round 11 global test acc  93.3900 

Rounds 12 filter noisy data:
